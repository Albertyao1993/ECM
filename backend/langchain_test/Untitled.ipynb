{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3eab31-671c-42d0-9546-1f70d0d5e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain_core\n",
    "import langchain_ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029c7669-89fc-4ff5-bccf-7a0f350da59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6abc8ade-56c5-4f15-8e20-396588c7bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "936d3461-77c7-4cbe-82f7-67a002a51104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template=\"Question: {question}\\n\\nAnswer: Let's think step by step.\"))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3e9b070-a482-4b25-b7a6-52786f94d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6437d1-8025-438c-af63-e1b23db4ccd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaLLM(model='llama3.2', _client=<ollama._client.Client object at 0x0000014D63446850>, _async_client=<ollama._client.AsyncClient object at 0x0000014D63425FD0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7e6c14-3f9e-4432-8b6a-39ab08d0da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "497e48e2-c820-4226-9991-b26e6ab01e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template=\"Question: {question}\\n\\nAnswer: Let's think step by step.\"))])\n",
       "| OllamaLLM(model='llama3.2', _client=<ollama._client.Client object at 0x0000014D63446850>, _async_client=<ollama._client.AsyncClient object at 0x0000014D63425FD0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d58c480d-01d3-4878-9a3e-b727746d140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.invoke(\"{question: can you be a smart home assistant for energy monitoring ?}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2abbdda-a99a-4ca4-9b14-87d7aa5f1b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To become a smart home assistant for energy monitoring, I\\'d need to consider the following steps:\\n\\n1. **Integration with Energy Meters**: First, I would need to integrate with various types of energy meters, such as smart plugs, smart thermostats, and energy monitors, to collect data on energy consumption in real-time.\\n\\n2. **Data Analysis and Processing**: Next, I would analyze and process the collected data to identify patterns, trends, and anomalies in energy usage. This could involve using machine learning algorithms to detect unusual energy consumption spikes or dips.\\n\\n3. **Alert System Implementation**: To help homeowners stay informed about their energy usage, I would implement an alert system that sends notifications when energy consumption exceeds certain thresholds, such as a high surge in electricity usage during peak hours.\\n\\n4. **Personalized Recommendations and Insights**: Based on the analyzed data, I could provide personalized recommendations and insights to help homeowners optimize their energy consumption, reduce waste, and lower their utility bills.\\n\\n5. **Voice Command Support**: To make myself more accessible, I would need to support voice commands, allowing homeowners to easily ask me questions like \"How much energy have I used today?\" or \"What\\'s my average daily electricity bill?\"\\n\\n6. **Integration with Home Automation Systems**: Finally, I could integrate with popular home automation systems, such as Amazon Alexa or Google Assistant, to provide seamless control over smart home devices and energy monitoring features.\\n\\nBy following these steps, I can become a comprehensive smart home assistant for energy monitoring, providing homeowners with valuable insights and tools to optimize their energy usage and reduce their environmental impact.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ab9ad-96e9-49e1-887d-c80b7fda844a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
